{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Using cross_val_score with skada\n\nThis example illustrates the use of DA scorer such as :class:`~skada.metrics.TargetAccuracyScorer`\nwith [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We first create a shifted dataset. Then we prepare the pipeline including a\nbase estimator doing the classification and the DA estimator. We use\n:code:`ShuffleSplit` as cross-validation strategy.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.model_selection import ShuffleSplit, cross_val_score\nfrom sklearn.svm import SVC\n\nfrom skada import EntropicOTMapping, make_da_pipeline, source_target_split\nfrom skada.datasets import make_shifted_datasets\nfrom skada.metrics import SupervisedScorer\n\nRANDOM_SEED = 0\ndataset = make_shifted_datasets(\n    n_samples_source=30,\n    n_samples_target=20,\n    shift=\"conditional_shift\",\n    label=\"binary\",\n    noise=0.4,\n    random_state=RANDOM_SEED,\n    return_dataset=True,\n)\n\nbase_estimator = SVC()\nestimator = EntropicOTMapping(base_estimator=base_estimator, reg_e=0.5, tol=1e-3)\n\nX, y, sample_domain = dataset.pack_train(as_sources=[\"s\"], as_targets=[\"t\"])\nX_source, X_target, y_source, y_target = source_target_split(\n    X, y, sample_domain=sample_domain\n)\ncv = ShuffleSplit(n_splits=5, test_size=0.3, random_state=RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The DA estimator pipeline is ready to be used with :code:`cross_val_score`.\nSource data from the training splits is first adapted with the target\ndata from the same splits and then used to fit the base estimator.\nThe target data from the test split is used to compute the score.\nThe separation between source and target data is done automatically\nby the DA pipeline thanks to :code:`sample_domain`. The :code:`target_labels`\nare only used by the :code:`SupervisedScorer`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "_, target_labels, _ = dataset.pack(as_sources=[\"s\"], as_targets=[\"t\"], train=False)\nscores_sup = cross_val_score(\n    estimator,\n    X,\n    y,\n    cv=cv,\n    params={\"sample_domain\": sample_domain, \"target_labels\": target_labels},\n    scoring=SupervisedScorer(),\n)\n\nprint(\n    \"Cross-validation score with supervised DA: \"\n    f\"{np.mean(scores_sup):.2f} (+/- {np.std(scores_sup):.2f})\"\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To evaluate the performance of the DA estimator, we compare it with the\nperformance of the base estimator without DA. We use the same cross-validation\nstrategy and the same data splits. We create a DA pipeline with\n:code:`make_da_pipeline` including the base estimator only. The\n:code:`sample_domain` and :code:`target_labels` are also passed to the pipeline\nto separate the source and target data and to compute the score.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "estimator_no_da = make_da_pipeline(base_estimator)\n\nscores_no_da = cross_val_score(\n    estimator_no_da,\n    X,\n    y,\n    cv=cv,\n    params={\"sample_domain\": sample_domain, \"target_labels\": target_labels},\n    scoring=SupervisedScorer(),\n)\n\nprint(\n    \"Cross-validation score without DA: \"\n    f\"{np.mean(scores_no_da):.2f} (+/- {np.std(scores_no_da):.2f})\"\n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6, 4))\nplt.barh(\n    [0, 1],\n    [np.mean(scores_sup), np.mean(scores_no_da)],\n    yerr=[np.std(scores_sup), np.std(scores_no_da)],\n)\nplt.yticks([0, 1], [\"DA\", \"No DA\"])\nplt.xlabel(\"Accuracy\")\nplt.axvline(0.5, color=\"k\", linestyle=\"--\", label=\"Random guess\")\nplt.legend()\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}