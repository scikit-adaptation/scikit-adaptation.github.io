{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Visualizing cross-validation behavior in skada\n\nThis illustrates the use of DA cross-validation object such as\n:class:`~skada.model_selection.DomainShuffleSplit`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's prepare the imports:\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Yanis Lalou\n#\n# License: BSD 3-Clause\n# sphinx_gallery_thumbnail_number = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nfrom matplotlib.patches import Patch\n\nfrom skada.datasets import make_shifted_datasets\nfrom skada.model_selection import (\n    DomainShuffleSplit,\n    LeaveOneDomainOut,\n    SourceTargetShuffleSplit,\n    StratifiedDomainShuffleSplit,\n)\n\nRANDOM_SEED = 0\ncmap_data = plt.cm.PRGn\ncmap_domain = plt.cm.RdBu\ncmap_cv = plt.cm.coolwarm\nn_splits = 4\n# Since we'll be using a dataset with 2 source and 2 target source,\n# the lodo splitter will generate only at most 4 splits\nn_splits_lodo = 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First we generate our datapoints. They are drawn from 4 different\ndistributions, 2 source and 2 target distributions. The target\ndistributions are shifted with respect to the source distributions.\nThus we will have a domain adaptation problem with 2 source domains\nand 2 target domains.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = make_shifted_datasets(\n    n_samples_source=3,\n    n_samples_target=2,\n    shift=\"concept_drift\",\n    label=\"binary\",\n    noise=0.4,\n    random_state=RANDOM_SEED,\n    return_dataset=True,\n)\n\ndataset2 = make_shifted_datasets(\n    n_samples_source=3,\n    n_samples_target=2,\n    shift=\"concept_drift\",\n    label=\"binary\",\n    noise=0.4,\n    random_state=RANDOM_SEED + 1,\n    return_dataset=True,\n)\ndataset.merge(dataset2, names_mapping={\"s\": \"s2\", \"t\": \"t2\"})\n\nX, y, sample_domain = dataset.pack_train(as_sources=[\"s\", \"s2\"], as_targets=[\"t\", \"t2\"])\n_, target_labels, _ = dataset.pack(\n    as_sources=[\"s\", \"s2\"], as_targets=[\"t\", \"t2\"], train=False\n)\n\n# Sort by sample_domain first then by target_labels\nindx_sort = np.lexsort((target_labels, sample_domain))\nX = X[indx_sort]\ny = y[indx_sort]\ntarget_labels = target_labels[indx_sort]\nsample_domain = sample_domain[indx_sort]\n\n\n# For Lodo methods\nX_lodo, y_lodo, sample_domain_lodo = dataset.pack_lodo()\n\nindx_sort = np.lexsort((y_lodo, sample_domain_lodo))\nX_lodo = X_lodo[indx_sort]\ny_lodo = y_lodo[indx_sort]\nsample_domain_lodo = sample_domain_lodo[indx_sort]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We\u2019ll define a function that lets us visualize the behavior of\neach cross-validation object.\nWe\u2019ll perform 4 splits (or 2 for the lodo method) of the data.\nOn each split, we\u2019ll visualize the indices chosen for\nthe training set (in blue) and the test set (in orange).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Code source: scikit-learn documentation\n# Modified for documentation by Yanis Lalou\n# License: BSD 3 clause\ndef plot_cv_indices(cv, X, y, sample_domain, ax, n_splits, lw=10):\n    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n    # Generate the training/testing visualizations for each CV split\n    cv_args = {\"X\": X, \"y\": y, \"sample_domain\": sample_domain}\n\n    for ii, (tr, tt) in enumerate(cv.split(**cv_args)):\n        # Fill in indices with the training/test sample_domain\n        indices = np.array([np.nan] * len(X))\n        indices[tt] = 1\n        indices[tr] = 0\n\n        # Visualize the results\n        ax.scatter(\n            [i / 2 for i in range(1, len(indices) * 2 + 1, 2)],\n            [ii + 0.5] * len(indices),\n            c=indices,\n            marker=\"_\",\n            lw=lw,\n            cmap=cmap_cv,\n            vmin=-0.2,\n            vmax=1.2,\n        )\n\n    # Plot the data classes and sample_domain at the end\n    ax.scatter(\n        [i / 2 for i in range(1, len(indices) * 2 + 1, 2)],\n        [ii + 1.5] * len(X),\n        c=y,\n        marker=\"_\",\n        lw=lw,\n        cmap=cmap_data,\n        vmin=-1.2,\n        vmax=0.2,\n    )\n\n    ax.scatter(\n        [i / 2 for i in range(1, len(indices) * 2 + 1, 2)],\n        [ii + 2.5] * len(X),\n        c=sample_domain,\n        marker=\"_\",\n        lw=lw,\n        cmap=cmap_domain,\n        vmin=-3.2,\n        vmax=3.2,\n    )\n\n    # Formatting\n    yticklabels = list(range(n_splits)) + [\"class\", \"sample_domain\"]\n    ax.set(\n        yticks=np.arange(n_splits + 2) + 0.5,\n        yticklabels=yticklabels,\n        ylim=[n_splits + 2.2, -0.2],\n        xlim=[0, len(X)],\n    )\n    ax.set_title(f\"{type(cv).__name__}\", fontsize=15)\n    return ax\n\n\ndef plot_lodo_indices(cv, X, y, sample_domain, ax, lw=10):\n    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n    # Generate the training/testing visualizations for each CV split\n    cv_args = {\"X\": X, \"y\": y, \"sample_domain\": sample_domain}\n\n    for ii, (tr, tt) in enumerate(cv.split(**cv_args)):\n        # Fill in indices with the training/test sample_domain\n        indices = np.array([np.nan] * len(X))\n        indices[tt] = 1\n        indices[tr] = 0\n\n        # Visualize the results\n        ax.scatter(\n            [i / 2 for i in range(1, len(indices) * 2 + 1, 2)],\n            [ii + 0.5] * len(indices),\n            c=indices,\n            marker=\"_\",\n            lw=lw,\n            cmap=cmap_cv,\n            vmin=-0.2,\n            vmax=1.2,\n            s=1.8,\n        )\n\n    # Plot the data classes and sample_domain at the end\n    ax.scatter(\n        [i / 2 for i in range(1, len(indices) * 2 + 1, 2)],\n        [ii + 1.5] * len(X),\n        c=y,\n        marker=\"_\",\n        lw=lw,\n        cmap=cmap_data,\n        vmin=-1.2,\n        vmax=0.2,\n    )\n\n    ax.scatter(\n        [i / 2 for i in range(1, len(indices) * 2 + 1, 2)],\n        [ii + 2.5] * len(X),\n        c=sample_domain,\n        marker=\"_\",\n        lw=lw,\n        cmap=cmap_domain,\n        vmin=-3.2,\n        vmax=3.2,\n    )\n\n    # Formatting\n    yticklabels = list(range(n_splits)) + [\"class\", \"sample_domain\"]\n    ax.set(\n        yticks=np.arange(n_splits + 2) + 0.5,\n        yticklabels=yticklabels,\n        ylim=[n_splits + 2.2, -0.2],\n        xlim=[0, len(X)],\n    )\n    ax.set_title(f\"{type(cv).__name__}\", fontsize=15)\n    return ax\n\n\ndef plot_st_shuffle_indices(cv, X, y, target_labels, sample_domain, ax, n_splits, lw):\n    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n    for n, labels in enumerate([y, target_labels]):\n        # Generate the training/testing visualizations for each CV split\n        cv_args = {\"X\": X, \"y\": labels, \"sample_domain\": sample_domain}\n        for ii, (tr, tt) in enumerate(cv.split(**cv_args)):\n            # Fill in indices with the training/test sample_domain\n            indices = np.array([np.nan] * len(X))\n            indices[tt] = 1\n            indices[tr] = 0\n\n            # Visualize the results\n            ax[n].scatter(\n                [i / 2 for i in range(1, len(indices) * 2 + 1, 2)],\n                [ii + 0.5] * len(indices),\n                c=indices,\n                marker=\"_\",\n                lw=lw,\n                cmap=cmap_cv,\n                vmin=-0.2,\n                vmax=1.2,\n            )\n\n        # Plot the data classes and sample_domain at the end\n        ax[n].scatter(\n            [i / 2 for i in range(1, len(indices) * 2 + 1, 2)],\n            [ii + 1.5] * len(X),\n            c=labels,\n            marker=\"_\",\n            lw=lw,\n            cmap=cmap_data,\n            vmin=-1.2,\n            vmax=0.2,\n        )\n\n        ax[n].scatter(\n            [i / 2 for i in range(1, len(indices) * 2 + 1, 2)],\n            [ii + 2.5] * len(X),\n            c=sample_domain,\n            marker=\"_\",\n            lw=lw,\n            cmap=cmap_domain,\n            vmin=-3.2,\n            vmax=3.2,\n        )\n\n        # Formatting\n        yticklabels = list(range(n_splits)) + [\"class\", \"sample_domain\"]\n        ax[n].set(\n            yticks=np.arange(n_splits + 2) + 0.5,\n            yticklabels=yticklabels,\n            ylim=[n_splits + 2.2, -0.2],\n            xlim=[0, len(X)],\n        )\n\n    return ax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following plot illustrates the behavior of\n:class:`~skada.model_selection.SourceTargetShuffleSplit`.\nThe left plot shows the indices of the training and\ntesting sets for each split and with the datased packed with\n:func:`~skada.datasets._base.DomainAwareDataset.pack_train`\n(the target domains labels are masked (=-1)).\nWhile the right plot shows the indices of the training and\ntesting sets for each split and with the datased packed with\n:func:`~skada.datasets._base.DomainAwareDataset.pack_test`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cvs = [SourceTargetShuffleSplit]\nfor cv in cvs:\n    fig, ax = plt.subplots(1, 2, figsize=(7, 3), sharey=True)\n    fig.suptitle(f\"{cv.__name__}\", fontsize=15)\n    plot_st_shuffle_indices(\n        cv(n_splits), X, y, target_labels, sample_domain, ax, n_splits, 10\n    )\n\n    fig.legend(\n        [Patch(color=cmap_cv(0.8)), Patch(color=cmap_cv(0.02))],\n        [\"Testing set\", \"Training set\"],\n        loc=\"center right\",\n    )\n    fig.text(0.48, 0.01, \"Sample index\", ha=\"center\")\n    fig.text(0.001, 0.5, \"CV iteration\", va=\"center\", rotation=\"vertical\")\n\n    # Make the legend fit\n    plt.tight_layout()\n    fig.subplots_adjust(right=0.7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following plot illustrates the behavior of\n:class:`~skada.model_selection.LeaveOneDomainOut`.\nThe plot shows the indices of the training and testing sets\nfor each split and which domain is used as the target domain\nfor each split.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cvs = [LeaveOneDomainOut]\nfor cv in cvs:\n    fig, ax = plt.subplots(figsize=(6, 3))\n    plot_lodo_indices(cv(n_splits_lodo), X_lodo, y_lodo, sample_domain_lodo, ax)\n\n    fig.legend(\n        [Patch(color=cmap_cv(0.8)), Patch(color=cmap_cv(0.02))],\n        [\"Testing set\", \"Training set\"],\n        loc=\"center right\",\n    )\n    fig.text(0.48, 0.01, \"Sample index\", ha=\"center\")\n    fig.text(0.001, 0.5, \"CV iteration\", va=\"center\", rotation=\"vertical\")\n\n    # Make the legend fit\n    plt.tight_layout()\n    fig.subplots_adjust(right=0.7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's see how the other\ncross-validation objects behave on our dataset.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cvs = [\n    DomainShuffleSplit,\n    StratifiedDomainShuffleSplit,\n]\n\nfor cv in cvs:\n    fig, ax = plt.subplots(figsize=(6, 3))\n    plot_cv_indices(cv(n_splits), X, y, sample_domain, ax, n_splits)\n\n    fig.legend(\n        [Patch(color=cmap_cv(0.8)), Patch(color=cmap_cv(0.02))],\n        [\"Testing set\", \"Training set\"],\n        loc=\"center right\",\n    )\n    fig.text(0.48, 0.01, \"Sample index\", ha=\"center\")\n    fig.text(0.001, 0.5, \"CV iteration\", va=\"center\", rotation=\"vertical\")\n\n    # Make the legend fit\n    plt.tight_layout()\n    fig.subplots_adjust(right=0.7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see each splitter has a very different behavior:\n  -   :class:`~skada.model_selection.SourceTargetShuffleSplit`: Each sample\n      is used once as a test set while the remaining samples\n      form the training set.\n  -   :class:`~skada.model_selection.DomainShuffleSplit`:\n      Randomly split the data depending on their sample_domain.\n      Each fold is composed of samples coming from all\n      source and target domains.\n  -   :class:`~skada.model_selection.StratifiedDomainShuffleSplit`: Same as\n      :class:`~skada.model_selection.DomainShuffleSplit` but by also\n      preserving the percentage of samples for each class and for each sample domain.\n      Split depends not only on the samples sample_domain but also their label.\n  -   :class:`~skada.model_selection.LeaveOneDomainOut`: Each sample with the same\n      sample_domain is used once as the target domain, while the remaining samples\n      from the others sample_domain for the source domain (Can be used only with\n      :func:`~skada.datasets._base.DomainAwareDataset.pack_lodo`)\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}