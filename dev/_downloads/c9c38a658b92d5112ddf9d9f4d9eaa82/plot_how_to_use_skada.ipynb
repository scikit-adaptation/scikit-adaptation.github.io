{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# How to use SKADA\n\nThis is a short example of how to use SKADA to perform domain adaptation\non a simple dataset will illustration of the API choice specific to DA.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Author: Remi Flamary\n#\n# License: MIT License\n# sphinx_gallery_thumbnail_number = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom sklearn.model_selection import GridSearchCV\nfrom skada.metrics import PredictionEntropyScorer\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom skada import CORALAdapter, GaussianReweightDensityAdapter\nfrom skada import make_da_pipeline\nfrom skada.model_selection import SourceTargetShuffleSplit\nfrom sklearn.svm import SVC\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import make_pipeline\nfrom skada import CORAL\nimport matplotlib.pyplot as plt\n\nfrom skada import source_target_split\nfrom skada.datasets import make_shifted_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DA dataset\n\nWe generate a simple 2D DA dataset. Note that DA data\nare organized with all source and target sample as follows:\n\n* :code:`X` is the input data\n* :code:`y` is the output data to be predicted (labels on target samples are not\n  used)\n* :code:`sample_domain` is the domain of each sample (integer <=0 for\n  source and >0 for target)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Get DA dataset\nX, y, sample_domain = make_shifted_datasets(\n    20, 20, shift=\"concept_drift\", random_state=42)\n\n# split source and target for visualization\nXs, Xt, ys, yt = source_target_split(X, y, sample_domain=sample_domain)\n\n# plot data\nplt.figure(1, (10, 5))\n\nplt.subplot(1, 2, 1)\nplt.scatter(Xs[:, 0], Xs[:, 1], c=ys, cmap='tab10', vmax=9, label=\"Source\")\nplt.title(\"Source data\")\nax = plt.axis()\n\nplt.subplot(1, 2, 2)\nplt.scatter(Xt[:, 0], Xt[:, 1], c=yt, cmap='tab10', vmax=9, label=\"Target\")\nplt.axis(ax)\nplt.title(\"Target data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DA Classifier estimator\n\nDA estimators are used exactly as regular estimators. The only difference is\nthat the :code:`sample_domain` array must be passed (by name).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# create a DA estimator\nclf = CORAL()\n\n# train on all data\nclf.fit(X, y, sample_domain=sample_domain)\n\n# estimator is designed to predict on target by default\nyt_pred = clf.predict(Xt)\n\n# accuracy on source and target\nprint('Accuracy on source:', clf.score(Xs, ys))\nprint('Accuracy on target:', clf.score(Xt, yt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-----------------------------\n\nDA estimators can be used as final estimator in the sklearn pipeline. The only\ndifference is that the :code:`sample_domain` array must be passed (by name)\nduring the fit.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# create a DA pipeline\npipe = make_pipeline(StandardScaler(), CORAL(base_estimator=SVC()))\npipe.fit(X, y, sample_domain=sample_domain)\n\nprint('Accuracy on target:', pipe.score(Xt, yt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DA Adapter pipeline\n\nMany DA method correspond to a data adapter that can be used to transform\ndata such that a regular estimator can be used. For those methods, skada\nprovides a :code:`Adapter` class that can be used in a DA pipeline from\n:code: .\n\nHere is an example with the CORAL and GaussianReweight adapter.\n\n.. WARNING::\n  Note that as illustrated below for\n  adapters that reweight the data, one needs a subsequent estimator that\n  requires the weighs as input. This can be done with :code:`set_fit_request`\n  method of the estimator by executing\n  :code:`.set_fit_request(sample_weight=True)`). If the estimator (for\n  pipeline or DA estimator) does not\n  require sample weights, the DA pipeline will raise an error.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# create a DA pipeline with CORAL adapter\npipe = make_da_pipeline(StandardScaler(), CORALAdapter(), SVC())\npipe.fit(X, y, sample_domain=sample_domain)\n\nprint('Accuracy on target:', pipe.score(Xt, yt))\n\n# create a DA pipeline with GaussianReweight adapter\npipe = make_da_pipeline(StandardScaler(),\n                        GaussianReweightDensityAdapter(),\n                        LogisticRegression().set_fit_request(sample_weight=True))\npipe.fit(X, y, sample_domain=sample_domain)\n\nprint('Accuracy on target:', pipe.score(Xt, yt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DA estimator with cross-validation of score\n\nDA estimators can be used with cross-validation as regular estimators using\nfunctions from sklearn. Note that the :code:`sample_domain` array must be\npassed in the :code:`params` dictionary of the :code:`cross_val_score` function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# splitter for cross-validation of score\ncv = SourceTargetShuffleSplit(random_state=0)\n\n# DA scorer not using target labels (not available in DA)\nscorer = PredictionEntropyScorer()\n\nclf = CORAL(SVC(probability=True))  # needs probability for entropy score\n\n# cross-validation\nscores = cross_val_score(clf, X, y, params={'sample_domain': sample_domain},\n                         cv=cv, scoring=scorer)\n\nprint('Entropy score: {:1.2f} (+-{:1.2f})'.format(scores.mean(), scores.std()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DA estimator with grid search\n\nDA estimators can be used with grid search as regular estimators using\nfunctions from sklearn. Note that the :code:`sample_domain` array must be\npassed in the :code:`fit` method of the grid search.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reg_coral = [0.1, 0.5, 1, \"auto\"]\n\nclf = make_da_pipeline(StandardScaler(), CORALAdapter(), SVC(probability=True))\n\n# grid search\ngrid_search = GridSearchCV(\n    estimator=clf,\n    param_grid={\"coraladapter__reg\": reg_coral},\n    cv=SourceTargetShuffleSplit(random_state=0),\n    scoring=PredictionEntropyScorer(),\n)\n\ngrid_search.fit(X, y, sample_domain=sample_domain)\n\nprint('Best regularization parameter:', grid_search.best_params_['coraladapter__reg'])\nprint('Accuracy on target:', np.mean(grid_search.predict(Xt) == yt))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}