{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Gradual Domain Adaptation Using Optimal Transport\n\nThis example illustrates the GOAT method from [38] on a simple classification task.\nHowever, the CNN is replaced with a MLP.\n\n.. [38] Y. He, H. Wang, B. Li, H. Zhao\n        Gradual Domain Adaptation: Theory and Algorithms in\n        Journal of Machine Learning Research, 2024.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Authors: F\u00e9lix Lefebvre and Julie Alberge\n#\n# License: BSD 3-Clause"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nfrom sklearn.inspection import DecisionBoundaryDisplay\nfrom sklearn.neural_network import MLPClassifier\n\nfrom skada import source_target_split\nfrom skada._gradual_da import GradualEstimator\nfrom skada.datasets import make_shifted_datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate conditional shift dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n, m = 20, 25  # number of source and target samples\nX, y, sample_domain = make_shifted_datasets(\n    n_samples_source=n,\n    n_samples_target=m,\n    shift=\"conditional_shift\",\n    noise=0.1,\n    random_state=42,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot source and target datasets\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "X_source, X_target, y_source, y_target = source_target_split(\n    X, y, sample_domain=sample_domain\n)\nlims = (min(X[:, 0]) - 0.5, max(X[:, 0]) + 0.5, min(X[:, 1]) - 0.5, max(X[:, 1]) + 0.5)\n\nn_tot_source = X_source.shape[0]\nn_tot_target = X_target.shape[0]\n\nplt.figure(1, figsize=(8, 3.5))\nplt.subplot(121)\n\nplt.scatter(X_source[:, 0], X_source[:, 1], c=y_source, vmax=9, cmap=\"tab10\", alpha=0.7)\nplt.title(\"Source domain\")\nplt.axis(lims)\n\nplt.subplot(122)\nplt.scatter(X_target[:, 0], X_target[:, 1], c=y_target, vmax=9, cmap=\"tab10\", alpha=0.7)\nplt.title(\"Target domain\")\nplt.axis(lims)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fit Gradual Domain Adaptation\n\nWe use a MLP classifier as the base estimator (default parameters).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "base_estimator = MLPClassifier(hidden_layer_sizes=(50, 50))\n\ngradual_adapter = GradualEstimator(\n    n_steps=40,  # number of adaptation steps\n    base_estimator=base_estimator,\n    advanced_ot_plan_sampling=True,\n    save_estimators=True,\n    save_intermediate_data=True,\n)\n\ngradual_adapter.fit(\n    X,\n    y,\n    sample_domain=sample_domain,\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check results\nCompute accuracy on source and target with the initial\nestimator and the final estimator.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clfs = gradual_adapter.get_intermediate_estimators()\n\nACC_source_init = clfs[0].score(X_source, y_source)\nACC_target_init = clfs[0].score(X_target, y_target)\n\nprint(f\"Initial accuracy on source domain: {ACC_source_init:.3f}\")\nprint(f\"Initial accuracy on target domain: {ACC_target_init:.3f}\")\nprint(\"\")\n\nACC_source = gradual_adapter.score(X_source, y_source)\nACC_target = gradual_adapter.score(X_target, y_target)\n\nprint(f\"Final accuracy on source domain: {ACC_source:.3f}\")\nprint(f\"Final accuracy on target domain: {ACC_target:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspect intermediate states\n\nWe can plot the intermediate datasets and decision boundaries.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "intermediate_data = gradual_adapter.intermediate_data_\n\nfig, axes = plt.subplots(2, 4, figsize=(12, 6))\naxes = axes.ravel()\n\n# Define which steps to plot\nsteps_to_plot = [5, 10, 15, 20, 25, 30, 35, 40]\n\nfor i, step in enumerate(steps_to_plot):\n    ax = axes[i]\n    X_step, y_step = intermediate_data[step - 1]\n    clf = clfs[step - 1]\n\n    ax.scatter(X_step[:, 0], X_step[:, 1], c=y_step, vmax=9, cmap=\"tab10\", alpha=0.7)\n    DecisionBoundaryDisplay.from_estimator(\n        clf,\n        X,\n        response_method=\"predict\",\n        cmap=\"gray_r\",\n        alpha=0.15,\n        ax=ax,\n        grid_resolution=200,\n    )\n    ax.set_title(f\"t = {step}\")\n    ax.axis(lims)\n\nplt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot decision boundaries on source and target datasets\n\nNow we can see how this gradual domain adaptation has changed\nthe decision boundary between the source and target domains.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "figure, axis = plt.subplots(1, 2, figsize=(9, 4))\ncm = \"gray_r\"\nDecisionBoundaryDisplay.from_estimator(\n    clfs[0],\n    X,\n    response_method=\"predict\",\n    cmap=cm,\n    alpha=0.15,\n    ax=axis[0],\n    grid_resolution=200,\n)\naxis[0].scatter(\n    X_source[:, 0],\n    X_source[:, 1],\n    c=y_source,\n    vmax=9,\n    cmap=\"tab10\",\n    alpha=0.7,\n)\naxis[0].set_title(\"Source domain\")\nDecisionBoundaryDisplay.from_estimator(\n    clfs[-1],\n    X,\n    response_method=\"predict\",\n    cmap=cm,\n    alpha=0.15,\n    ax=axis[1],\n    grid_resolution=200,\n)\naxis[1].scatter(\n    X_target[:, 0],\n    X_target[:, 1],\n    c=y_target,\n    vmax=9,\n    cmap=\"tab10\",\n    alpha=0.7,\n)\naxis[1].set_title(\"Target domain\")\n\naxis[0].text(\n    0.05,\n    0.1,\n    f\"Accuracy: {clfs[0].score(X_source, y_source):.1%}\",\n    transform=axis[0].transAxes,\n    ha=\"left\",\n    bbox={\"boxstyle\": \"round\", \"facecolor\": \"white\", \"alpha\": 0.5},\n)\naxis[1].text(\n    0.05,\n    0.1,\n    f\"Accuracy: {gradual_adapter.score(X_target, y_target):.1%}\",\n    transform=axis[1].transAxes,\n    ha=\"left\",\n    bbox={\"boxstyle\": \"round\", \"facecolor\": \"white\", \"alpha\": 0.5},\n)\n\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}